---
title: "rbmi: Advanced Functionality"
output: 
  bookdown::html_document2:
    toc: true
    toc_depth: 4
    number_sections: true
    citation_package: natbib
    base_format: rmarkdown::html_vignette
bibliography: "references.bib"
link-citations: true   
linkcolor: blue
vignette: >
  %\VignetteIndexEntry{rbmi: Advanced Functionality}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>"
)
```


# Introduction

The purpose of this vignette is to provide an overview of some of the more advanced
features of the `rbmi` package. 

# Data simulation {#sec:dataSimul}

In order to demonstrate the advanced functions we will first create a simulated dataset with the `rbmi` function `simulate_data()`.
A reader interested in other sections of the vignette must not necessarly read through this section.
The `simulate_data()` function generates data for a two-arms clinical trial with longitudinal continuous outcome and two intercurrent events (ICEs).
One intercurrent event (ICE1) may be thought of as a discontinuation from study treatment due to study drug or condition related (SDCR) reasons.
The other one (ICE2) may be thought of as discontinuation from study treatment due to uninformative study drop-out.
For the purposes of this vignette we consider the following scenario which is similar to the simulation study used in @Wolbers2021.
It is a trial of an active drug versus placebo with 100 subjects per group and 6 post-baseline assessments (bi-monthly visits until 12 months):

- The mean outcome trajectory in the placebo group (and in the active group under the null hypothesis) increased linearly from 50 at baseline to 60 at visit 6.
- The mean outcome trajectory in the active group was identical to the placebo group up to visit 2. From visit 2 onward, the slope decreased by 50% to 5 points/year.
- The covariance structure of the baseline and follow-up values in both groups was implied by a random intercept and slope model with a standard deviation of 5 for both the intercept and the slope, and a correlation of 0.25. In addition, an independent residual error with standard deviation 2.5 was added to each assessment.  
- The probability of study drug discontinuation after each visit was calculated according to a logistic model which also depended on the observed outcome at that visit. Specifically, a visit-wise discontinuation probability of 1.5% and 2.5% in the placebo and active group, respectively, was specified if the observed outcome was 50. For outcomes above 50, the odds of discontinuation further increase by 20% for each 1 point increase. 
- Study drug discontinuation had no effect on the mean trajectory in the placebo group. In the active group, subjects who discontinued followed the slope of the mean trajectory from the placebo group from that time point onward (CIR). 
- Study drop-out at the study drug discontinuation visit occurred with a probability of 75% leading to missing outcome data from that time point onward.

This scenario can be implemented as follows:


```{r}
library(rbmi)
library(dplyr)

set.seed(135)
n <- 100
time <- seq(0, 12, by = 2)

# Mean trajectory control
muC <- 50 + (10 / 12) * time

# Mean trajectory intervention
muT <- 50 + (10 / 12) * time - (5 / 12) * pmax(time - 4, 0)

# Create Sigma
sd_intercept <- 5
sd_slope <- 5
cor_slopeInter <- 0.25
sd_error <- 2.5
covRE <- matrix(
    c(
        sd_intercept^2,
        cor_slopeInter * sd_intercept * sd_slope,
        cor_slopeInter * sd_intercept * sd_slope,
        sd_slope^2
    ),
    ncol = 2
)

Sigma <- cbind(1, time / 12) %*% covRE %*% rbind(1, time / 12) + diag(sd_error^2, nrow = length(time))

# Set probability of discontinuation
probDisc_C <- 0.015
probDisc_T <- 0.025
or_outcome <- 1.20 # 1 point increase => +20% probability of discontinuation

# Set drop-out rate following discontinuation
prob_postDisc_dropout <- 0.75

# Set simulation parameters of the control arm
parsC <- set_simul_pars(
    mu = muC,
    sigma = Sigma,
    n = n,
    prob_ice1 = probDisc_C,
    or_outcome_ice1 = or_outcome,
    prob_post_ice1_dropout = prob_postDisc_dropout
)

# Set simulation parameters of the active arm
parsT <- parsC
parsT$mu <- muT
parsT$prob_ice1 <- probDisc_T

# Set assumption about post-ice trajectory
post_ice_traj <- "CIR"

# Simulate data
data <- simulate_data(
    pars_c = parsC,
    pars_t = parsT,
    post_ice_traj = post_ice_traj
)
```

Note that `simulate_data()` requires 3 arguments: 

- `pars_c`: The simulation parameters of the control arm
- `pars_t`: The simulation parameters of the intervention arm
- `post_ice_traj`: Specify how observed outcomes occurring after ICE1 are simulated

For more information about this function, please refer to the function documentation `help(simulate_data)`.

# Management of post-ICE observed values handled with a reference-based assumption {#sec:postICEobs}

The simulated trial explained in section \@ref(sec:dataSimul) assumes that outcomes in the active arm observed after the ICE "treatment discontinuation" follow the increments observed in the control arm.
Thus the imputation of missing data in the active arm after treatment discontinuation might be performed under the CIR assumption. How `rbmi` deals with observed values after an ICE handled using a reference-based method, is to include them in the analysis model but exclude them from the imputation model.

Let's first set-up the estimator: Suppose that imputation model has the mean change from baseline as the outcome, includes the treatment group, the (categorical) visit, treatment-by-visit interactions, the baseline outcome, and baseline outcome-by-visit interactions as covariates, and assumes a common unstructured covariance matrix in both groups.
The analysis model is ANCOVA that also adjusts for the baseline outcome value. Below we report the code to set the variables of the imputation and analysis models.
For details on the basic set-up to call the key rbmi functions, please refer to the "quickstart" vignette (`vignette("quickstart")`).

```{r}

# Create data_ice: CIR strategy for each patient in the active arm who stops the treatment
data_ice_CIR <- data %>%
    group_by(id = factor(id, levels = unique(id))) %>%
    mutate(
        is_interv = group == "Intervention",
        has_ice = any(ind_ice1 == 1)
    ) %>%
    filter(is_interv & has_ice) %>% # Select pts in active arm that disc from treatment
    summarise(
        visit = visit[ind_ice1 == 1][1] # Select first visit affected by the ICE
    )
data_ice_CIR$strategy <- "CIR"

# Compute change from baseline
data$change <- data$outcome - data$outcome_bl

# Remove rows corresponding to baseline visit
data <- data[data$visit %in% levels(data$visit)[-1], ]
data$visit <- factor(data$visit, levels <- unique(data$visit))

vars <- set_vars(
    subjid = "id",
    visit = "visit",
    outcome = "change",
    group = "group",
    covariates = c("visit*outcome_bl", "visit*group"),
    strategy = "strategy"
)

vars_an <- vars
vars_an$covariates <- "outcome_bl"

```

Let's assume that the chosen multiple imputation (MI) method is the approximate Bayesian MI with 10 imputations that can be set with the function `method_approxbayes()` as follows:

```{r}
method <- method_approxbayes(n_sample = 10)
```

We can now call sequentially the 4 key functions of `rbmi` to perform the multiple imputation.
Please note that the management of post-discontinuation observed data is performed without additional complexity for the user.
`draws()` automatically excludes post-ICE data handled with a reference-based method using information provided by the argument `data_ice`.
`impute()` will impute only actual missing data in `data[[vars$outcome]]`.

```{r}
set.seed(123)
draw_obj <- draws(
    data = data,
    data_ice = data_ice_CIR,
    vars = vars,
    method = method
)

impute_obj_CIR <- impute(
    draw_obj,
    references = c("Control" = "Control", "Intervention" = "Intervention")
)

ana_obj_CIR <- analyse(
    impute_obj_CIR,
    vars = vars_an
)

pool(ana_obj_CIR)
```

# Adding time-varying covariates in the imputation model

`rbmi` allows to include time-varying covariates in the imputation model.
For example, lets suppose that we want to implement an estimator equivalent to the one described in section \@ref(sec:postICEobs) with the following differences:

- There is an additional time-varying covariate that represents the number of visits from the ICE treatment discontinuation. This is set equal to 0 up to the treatment discontinuation and to the time from treatment discontinuation
at subsequent visits. Additionally a treatment by time-varying covariate interaction terms is included in the model. This variable allows to estimate the post-ICE trajectory in each arm directly from the data, without explicitly making apriori any (reference-based) assumption.
- The imputation is performed under MAR.

Indeed, one could assume that post-ICE data are missing-at-random after taking into account baseline characteristics, observed outcomes and additional information regarding the time of the ICE. For a precise description of this approach, we refer to @Guizzaro2021.

Let's first compute the time-varying covariate:

```{r}
data <- data %>%
    group_by(id) %>%
    mutate(time_from_ice1 = cumsum(ind_ice1))
```

and include it in the imputation model, crossed with the `group` variable:

```{r}
vars_tv <- set_vars(
    subjid = "id",
    visit = "visit",
    outcome = "change",
    group = "group",
    covariates = c("visit*outcome_bl", "visit*group", "time_from_ice1*group"),
    strategy = "strategy"
)
```

We can now call sequentially the 4 key `rbmi` functions:

```{r}
draw_obj <- draws(
    data = data,
    data_ice = NULL, # if NULL, MAR is assumed for every missing data
    vars = vars_tv,
    method = method
)

impute_obj_tv <- impute(
    draw_obj,
    references = c("Control" = "Control", "Intervention" = "Intervention")
)

ana_obj_tv <- analyse(
    impute_obj_tv,
    vars = vars_an
)

pool(ana_obj_tv)
```

# Efficiently Changing Imputation Strategies

The `draws()` function is by far the most computationally intensive function in `rbmi`.
In some settings, it may be important to explore the impact of a different
reference-based imputation strategy than the one chosen for the main analysis.
This change in the imputation strategy does not affect the imputation model but it does
affect the subsequent imputation step. 
In order to allow changes in the imputation strategy without having to re-run the 
`draws()` function, the function `impute()` has an additional argument `update_strategies`.

Please note though that this functionality comes with a some key limitations:
From a theoretical point of view, such updates are only sensible if the base imputation model and the data to which it is fitted are also applicable to the revised imputation strategy.
For example, as described in `help("draws", "rbmi")`, observed post-ICE data are included in the imputation model for the MAR strategy but excluded for non-MAR strategies.
For this reason, the imputation strategy cannot be changed from MAR to a non-MAR strategy in the presence of observed data after the ICE.
Likewise, a change from a non-MAR to MAR in the presence of observed data after the ICE triggers a warning because the imputation model was not fitted to all relevant data and may be inefficient.
Similarly, it is not possible to change the first visit which is affected by an ICE via argument `update_strategies`. 

As an example, let's assume we adopt the copy increments from reference strategy for the main analysis and explore the jump to reference imputation strategy as a sensitivity analysis.
If we use approximate Bayesian multiple imputation with 10 random imputation, this could be implemented as follows:

```{r}

set.seed(123)
draw_obj <- draws(
    data = data,
    data_ice = data_ice_CIR,
    vars = vars,
    method = method_approxbayes(n_sample = 10)
)

impute_obj_CIR <- impute(
    draw_obj,
    references = c("Control" = "Control", "Intervention" = "Intervention")
)

ana_obj_CIR <- analyse(
    impute_obj_CIR,
    vars = vars_an
)

pool(ana_obj_CIR)

## Now we re-use our draws samples but using the Jump to Reference
## Imputation strategy

data_ice_JR <- data_ice_CIR
data_ice_JR$strategy <- "JR"
data_ice_JR

impute_obj_JR <- impute(
    draw_obj,
    references = c("Control" = "Control", "Intervention" = "Intervention"),
    update_strategy = data_ice_JR
)

ana_obj_JR <- analyse(
    impute_obj_JR,
    vars = vars_an
)

pool(ana_obj_JR)
```


# Custom Imputation Strategies

The following imputation strategies are implemented in `rbmi`:

- Missing at Random (MAR)
- Jump to Reference (JR)
- Copy Reference (CR)
- Copy Increments from Reference (CIR)
- Last Mean Carried Forward (LMCF)

In addition, `rbmi` allows the user to implement their own imputation strategy. 
To do this there are three things which the user needs to do:

1. Define their own imputation strategy function. 
2. Specify which patients use this strategy in the `data_ice` dataset provided to `draws()`.
3. Provide the imputation strategy function to `impute()`.

The imputation strategy function must take 3 arguments (`pars_group`, `pars_ref`, and `index_mar`) and calculates the marginal mean trajectory and covariance matrix of a subject's marginal imputation distribution which will then be applied to subjects to which the strategy applies. 
Here, `pars_group` contains the predicted mean trajectory (`pars_group$mu`, a numeric vector) and covariance matrix (`pars_group$sigma`) for a subject conditional on their assigned treatment group and covariates.
`pars_ref` contains the corresponding mean trajectory and covariance matrix conditional on the reference group and the subject's covariates.
`index_mar` is a logical vector which specifies for each visit whether the visit is unaffected by an ICE handled using reference-based methods or not.
As an example, the user can check how the CIR strategy was implemented by looking at function `strategy_CIR()`.

```{r}
strategy_CIR
```

To further illustrate this for a simple example, assume that a strategy is to be implemented according to which the marginal mean of the imputation distribution is equal to the marginal mean trajectory for the subject according to their assigned group and covariates up to the ICE and equal to the average of the visit-wise marginal means based on the subjects covariates and the assigned group or the reference group, respectively.
For the covariance matrix of the marginal imputation distribution, the covariance matrix from the assigned group is taken. 


To do this, we first need to define the imputation function which for this example could be coded as: 

```{r}
strategy_AVG <- function(pars_group, pars_ref, index_mar) {
    mean_xy <- function(x, y) mean(c(x, y))
    mu_mean <- mapply(
        mean_xy,
        pars_group$mu,
        pars_ref$mu,
        SIMPLIFY = T
    )
    x <- pars_group
    x$mu[!index_mar] <- mu_mean[!index_mar]
    return(x)
}
```

And an example showing its use:
```{r}
pars_group <- list(
    mu = c(1, 2, 3),
    sigma = as_vcov(c(1, 3, 2), c(0.4, 0.5, 0.45))
)

pars_ref <- list(
    mu = c(5, 6, 7),
    sigma = as_vcov(c(2, 1, 1), c(0.7, 0.8, 0.5))
)

index_mar <- c(TRUE, TRUE, FALSE)

strategy_AVG(pars_group, pars_ref, index_mar)
```

To incorporate this into `rbmi`, `data_ice` needs to be updated such that subjects are 
specified as using the `AVG` imputation strategy. Additionally, the function needs
to be provided to `impute()` via the `getStrategies()` function as shown below:

```{r}
dat_ice <- data_ice_CIR
dat_ice$strategy <- "AVG"
dat_ice

draw_obj <- draws(
    data = data,
    data_ice = dat_ice,
    vars = vars,
    method = method
)

impute_obj <- impute(
    draw_obj,
    references = c("Control" = "Control", "Intervention" = "Intervention"),
    strategies = getStrategies(AVG = strategy_AVG)
)
```

# Custom Analysis Functions

By default `rbmi` will analyse the data by using the `ancova()` function as the analysis function which fits 
an ANCOVA model to the outcomes from each visit separately,
and returns the "treatment effect" estimate as well as the corresponding least square means
for each group. If the user wants to perform a different analysis, or return different
statistics from the analysis, then this can be done by using a custom analysis function.
Beware that for conditional mean imputation, the consistency of treatment effect estimation
has only been formally established for analysis functions corresponding to linear models (such as ANCOVA) and caution is 
required when applying alternative analysis functions.

The custom analysis function must take a `data.frame` as its 
first argument and return a named `list` with each element itself being a `list`
containing a at a minimum a point estimate, called `est`. 
For method `method_bayes()` or `method_approxbayes()`, the list must additionally contain a 
standard error (element `se`) and, if available, the degrees of freedom of the complete-data analysis model (element `df`). 

As an example, let's say that the analysis compares the proportion of subjects with an outcome > 60 at the last 
visit between the groups with baseline outcome as additional covariate. This could then lead to the following (naive) analysis function:

```{r}
compare_prop_lastvisit <- function(data, ...) {

    fit <- summary(
        glm(
            I(outcome > 60) ~ group + outcome_bl,
            family = binomial(),
            data = data[data[["visit"]] == "6", ]
        )
    )

    res <- list(
        trt = list(
            est = fit$coefficients["groupIntervention", "Estimate"],
            se = fit$coefficients["groupIntervention", "Std. Error"],
            df = Inf
        )
    )

    return(res)
}
```

The user should be aware that according to Rubin's rules, if the degrees of freedom from the complete-data analysis model is infinite, this does not imply that the pooled degrees of freedom is also infinite.
It can be proven that in this case the pooled degrees of freedom is `(M-1)/lambda^2`, where `M` is the number of imputations and `lambda` is the fraction of missing information.
Please see @Barnard1999 for details. If you want to force the pooled degrees of freedom to be `Inf`, please set `df = NA` as returned value from the analysis function.

This analysis function can then be used in combination with `analyse()` as follows:

```{r}
anl_obj <- analyse(
    imputations = impute_obj_CIR,
    fun = compare_prop_lastvisit)

pool(anl_obj)
```

# Delta Adjustment

A delta-adjustment refers to a shift in the distribution of the (unobserved) outcome values by a certain amount. This might be used to perform sensitivity analyses.
In the context of multiple imputation (MI), this is typically done by adding a fixed amount to the imputed values used in the primary analysis.
This implies that the delta-adjustment can be performed prior to the third stage of the MI process: The fit of the analysis model (`analyse()`).
That is, there is no additional consistent computational time needed to perform this type of sensitivity analysis since there is no need to re-fit the imputation model.
For details, please see @CroEtAlTutorial2020.

## Manually set `delta` {#sec:manualDelta}

The `delta` argument of `analyse()` allows users to modify the outcome variable prior to the analysis.
To do this, the user needs to provide a `data.frame` containing a column for the subject
and visit which identifies the observation to be adjusted, and then a 3rd column called `delta` which specifies the value which will be added to the outcome. 

The `delta_template()` function helps the user to set the desired delta-adjustment: it creates a skeleton `data.frame` containing 1 row per subject per visit with the value of delta set to 0 for all observations.

```{r}
dat_delta <- delta_template(imputations = impute_obj_CIR)
head(dat_delta)
```

Note that the output of `delta_template()` contains additional information that can be used to properly set the delta.

Using the example described in section \@ref(sec:dataSimul), let's say that we want to perform a delta-strategy where the delta applies to all imputed data after treatment discontinuation (regardless of the treatment arm).
Assume that we want to fix `delta` proportional to the unadjusted observed mean change from baseline of the outcome value over all trial population.
That is, we add `delta` to an imputed data after treatment discontinuation at a given visit proportional to the observed mean change from baseline at that visit.
Let's first determine the observed mean change from baseline at each visit:

```{r}
# Estimate mean change from baseline at each visit
mean_chg <- data %>%
    group_by(visit) %>%
    summarise(delta = mean(change, na.rm = TRUE))
mean_chg
```
Note that `na.rm = TRUE` is used to ignore the missing data.

Suppose that we want to apply a delta equal to the $20\%$ of the mean change from baseline, i.e.: 
```{r} 
deltas <- mean_chg
deltas$delta <- 0.2 * mean_chg$delta
deltas
```

Let's include this amount of delta in the `delta_template()` dataset:

```{r}

# Select observations corresponding to missing values after the ICE
index_delta <- dat_delta$is_missing & dat_delta$is_post_ice

# Include the value of delta from "mean_chg" to "dat_delta" by joining the two data.frames
dat_delta[index_delta, ] <- dat_delta %>%
    filter(is_missing & is_post_ice) %>%
    select(-delta) %>%
    left_join(deltas, by = "visit")
```

Note that the delta is applied only to observations that were missing and that were after the ICE "treatment discontinuation". 

We can now call `analyse()`, that will first add the delta to the corresponding outcomes and then call the analysis model.
Be aware that the delta is applied to all imputed datasets:

```{r}
# Repeat analyses with the delta-adjusted values and pool together the results
anl_delta <- analyse(impute_obj_CIR, delta = dat_delta, vars = vars_an)
pool(anl_delta)
```

## Tipping point analysis

The tipping point analysis is a way of doing sensitivity analysis by repeatedly performing a delta-adjustment with worse and worse value of delta until when the result from the primary analysis is overturned.

In the previous section (\@ref(sec:manualDelta)) we have added a delta to any imputed value after treatment discontinuation proportional to the observed mean change from baseline at the corresponding visit.
We have set the proportion equal to 20%. We can vary the proportion up to when the treatment effect estimated at the last visit is not significant anymore.

Let's start by writing a function that performs a delta-adjustment based on a proportion of the observed mean change from baseline.
This function needs as arguments the object resulting from the imputation phase (`impute_obj`), a `data.frame` containing the mean change from baseline at each visit (`mean_chg`) and a number indicating the chosen proportion (`prop`):

```{r}
delta_adj <- function(impute_obj, mean_chg, prop) {

    # Get delta template dataset
    dat_delta <- delta_template(imputations = impute_obj)

    # Estimate delta values
    mean_chg$delta <- prop * mean_chg$delta

    # Select observations corresponding to missing values after the ICE
    index_delta <- dat_delta$is_missing & dat_delta$is_post_ice

    # Include the value of delta from "mean_chg" to "dat_delta" by joining the two data.frames
    dat_delta[index_delta, ] <- dat_delta %>%
        filter(is_missing & is_post_ice) %>%
        select(-delta) %>%
        left_join(mean_chg, by = "visit")

    # Repeat analyses with the delta-adjusted values and pool together the results
    anl_delta <- analyse(impute_obj, delta = dat_delta, vars = vars_an)
    pool_obj <- pool(anl_delta)

    # Return the results together with the proportion used and the delta values
    pool_obj$prop <- prop
    pool_obj$delta <- mean_chg
    return(pool_obj)
}

```

To perform the tipping point analysis, we loop over increasing values of the proportion and we stop when the p-value is above the desired confidence level (we assume that it is equal to 0.05).

```{r}
prop <- seq(from = 0.1, to = 1, by = 0.1)

iter <- 1
p_val <- 0
while (p_val <= 0.05 & iter <= length(prop)) {

    # Perform analysis with current "prop"
    curr_res <- delta_adj(impute_obj, mean_chg, prop = prop[iter])

    # Extract p-value
    p_val <- curr_res$pars$trt_6$pvalue

    iter <- iter + 1
}

curr_res$prop
curr_res$delta
```


```{r, echo=FALSE}
v1 <- curr_res$prop * 100
v2 <- round(curr_res$delta$delta[curr_res$delta$visit == "6"], 3)
v3 <- prop[iter - 2] * 100
v4 <- prop[iter - 1] * 100
v5 <- prop[iter - 2] * 100
v6 <- prop[iter - 1] * 100
```



The p-value is estimated to be above the significance level when a delta equal to the `r v1`% of the mean change from baseline is applied. This correspond to a delta applied at the last visit equal to `r v2`.
Thus the "tipping point" happened somewhere between a delta equal to the `r v3`% and the `r v4`% of the mean change from baseline.
To get a more precise tipping point, one could repeat the tipping point analysis varying the proportion parameter from `r v5`% and the `r v6`%.

## Usage of `dlag` and `delta` arguments of `delta_template()`

The `delta` argument of `analyse()` allows users to modify the outcome variable
which can be utilised as part of a tipping point or sensitivity analysis. To do 
this, the user needs to provide a `data.frame` containing a column for the subject
and visit which identifies the observation to be adjusted, and then a 3rd column
called `delta` which specifies the value which will be added to the outcome prior to the analysis. 

The `delta_template()` function helps the user to set the desired delta-adjustment: it creates a skeleton `data.frame` containing
1 row per subject per visit with the value of delta set to 0 for all observations. The `delta_template()` function has two optional additional arguments `delta`
and `dlag` which allow the user to specify initial cumulative delta values based upon a
default value and a scaling coefficient based upon how far away the visit
in question is from the ICE visit. 

More specifically; the `delta` argument specifies the default amount of delta
that should be applied to each post-ICE visit, whilst
`dlag` specifies the scaling coefficient to be applied based upon the visits proximity
to first visit affected by the ICE. By default, the delta will only be added to unobserved (i.e. imputed) post-ICE 
outcomes but this can be changed by setting the optional argument `missing_only = FALSE`.

The usage of the `delta` and `dlag` arguments is best illustrated with a few examples:

Let `delta = c(5,6,7,8)` and `dlag=c(1,2,3,4)` (i.e. assuming there are 4 visits) and lets 
say that the subject's first visit affected by the ICE is visit 2. The calculation would then be as follows:

```
v1  v2  v3  v4
--------------
 5   6   7   8  # delta assigned to each visit
 0   1   2   3  # scaling starting from the first visit after the subjects ICE
--------------
 0   6  14  24  # delta * scaling
--------------
 0   6  20  44  # accumulative sum / delta to be applied to each visit
```

That is to say the subject would have a delta offset of 0 applied for visit v1, 6 for 
visit v2, 20 for visit v3 and 44 for visit v4. As a comparison, lets say that the subject 
instead that the subject's first visit affected by the ICE was visit 3. Then, would be as follows:

```
v1  v2  v3  v4
--------------
 5   6   7   8  # delta assigned to each visit
 0   0   1   2  # scaling starting from the first visit after the subjects ICE
--------------
 0   0   7  16  # delta * scaling
--------------
 0   0   7  23  # accumulative sum / delta to be applied to each visit
 ```
 
If one alternatively wanted to apply a constant delta value of 5 to all visits affected by the ICE
regarrdless of their proximity to the first ICE visit, this could be achieved
by setting `delta = c(5,5,5,5)` and `dlag = c(1,0,0,0)`. For example lets say the first visit v1 
was already affected by the ICE for a subject. Then the calculation would be as follows:

```
v1  v2  v3  v4
--------------
 5   5   5   5  # delta assigned to each visit
 1   0   0   0  # scaling starting from the first visit after the subjects ICE
--------------
 5   0   0  0  # delta * scaling
--------------
 5   5   5  5  # accumulative sum / delta to be applied to each visit
 ```

!!! I tried to clean up the wording accordingly but ran into some problems. Please help to fix this! 

Another way of using these arguments is to set delta to be the difference in time 
between visits and dlag to be the amount of delta per unit of time. For example 
lets say that we have a visit on weeks 1, 5, 6 & 9 and that we want a delta of 3
to be applied for each week after an ICE. This can be achieved by setting 
`delta = c(0,4,1,3)` (the difference in weeks between each visit) and `dlag = c(3/2, 3, 3, 3)`. 
For example subjects who experienced an ICE between visit v1 and v2 we might assume that the ICE happened at half way between the two visits, that is, at week 3. Then the first visit affected by the ICE would be visit v2 (i.e at week 5) and
the calculation would be:

```
v1  v2  v3  v4
--------------
 0   4   1   3  # delta assigned to each visit
 0   3/2   3   3  # scaling starting from the first visit after the subjects ICE 
--------------
 0   6   3   9  # delta * scaling
--------------
 0   0   3  12  # accumulative sum / delta to be applied to each visit
```

i.e. on week-6 (1 week after the ICE) they have a delta of 3 and on week-9 (4 weeks
after the ICE) they have a delta of 12.


To show this in action, lets say that we want a constant delta of 2 to be applied (regardless of
the lag) to all unobserved post-ICE visits in the treatment arm only. This can be achieved as follows:

First use the `delta` and `dlag` arguments of `delta_template()` to setup a template `data.frame`
in which every unobserved post-ICE visit has a delta of 2:
```{r}
delta_df <- delta_template(
    impute_obj_CIR,
    delta = c(2, 2, 2, 2, 2, 2),
    dlag = c(1, 0, 0, 0, 0, 0)
)

as_tibble(delta_df)
```

Next we can use the additional metadata variables provided by `delta_template()` to  manually 
reset the delta values for the control group back to 0:
```{r}
delta_df2 <- delta_df %>%
    mutate(delta = if_else(group == "Control", 0, delta))

as_tibble(delta_df2)
```

Finally we can now use our delta `data.frame` to apply our desired delta offset to our analysis:
```{r}
anl_delta <- analyse(impute_obj_CIR, delta = delta_df2, vars = vars_an)
pool(anl_delta)
```

# References
